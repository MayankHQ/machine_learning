{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwPJr79bqNR3qdTst7SoXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MayankHQ/machine_learning/blob/main/GradientDescent_GradientBoosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saXMRBHCYdWU",
        "outputId": "9b2048c9-fa3d-4225-dca1-b40c06686b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: x = 8.00, Slope = 20.00\n",
            "Step 1: x = 6.40, Slope = 16.00\n",
            "Step 2: x = 5.12, Slope = 12.80\n",
            "Step 3: x = 4.10, Slope = 10.24\n",
            "Step 4: x = 3.28, Slope = 8.19\n",
            "Step 5: x = 2.62, Slope = 6.55\n",
            "Step 6: x = 2.10, Slope = 5.24\n",
            "Step 7: x = 1.68, Slope = 4.19\n",
            "Step 8: x = 1.34, Slope = 3.36\n",
            "Step 9: x = 1.07, Slope = 2.68\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. The Function: y = x^2 (A simple bowl shape)\n",
        "# The derivative (slope) is 2x\n",
        "def gradient(x):\n",
        "    return 2 * x\n",
        "\n",
        "# 2. Setup\n",
        "current_x = 10  # We start at x=10 (High up on the hill)\n",
        "learning_rate = 0.1\n",
        "steps = [] # To store our path\n",
        "\n",
        "# 3. The Loop (Walking down the hill)\n",
        "for i in range(10):\n",
        "    steps.append(current_x)\n",
        "\n",
        "    # --- THE MAGIC FORMULA ---\n",
        "    # New = Old - (Learning Rate * Slope)\n",
        "    slope = gradient(current_x)\n",
        "    current_x = current_x - (learning_rate * slope)\n",
        "\n",
        "    print(f\"Step {i}: x = {current_x:.2f}, Slope = {slope:.2f}\")\n",
        "\n",
        "# You will see 'x' getting closer and closer to 0!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create Dummy Data (y = 3x + 5 roughly)\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([5, 7, 9, 11, 13]) # Exactly 2x + 3 actually. Let's see if it finds m=2, c=3.\n",
        "\n",
        "# 2. Initialize Parameters (Start from scratch)\n",
        "m_current = 0\n",
        "c_current = 0\n",
        "\n",
        "learning_rate = 0.01 # Step size\n",
        "epochs = 1000   # Number of steps\n",
        "n = len(X)           # Number of data points\n",
        "\n",
        "# 3. The Training Loop (Gradient Descent)\n",
        "for i in range(epochs):\n",
        "    # A. Make a prediction with current m and c\n",
        "    y_predicted = (m_current * X) + c_current\n",
        "\n",
        "    # B. Calculate the Derivatives (The Slope of the Error)\n",
        "    # How much is 'm' wrong?\n",
        "    dm = (-2/n) * sum(X * (y - y_predicted))\n",
        "\n",
        "    # How much is 'c' wrong?\n",
        "    dc = (-2/n) * sum(y - y_predicted)\n",
        "\n",
        "    # C. Update the values (Move down the hill)\n",
        "    m_current = m_current - (learning_rate * dm)\n",
        "    c_current = c_current - (learning_rate * dc)\n",
        "\n",
        "    # Print progress every 100 steps\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Epoch {i}: m = {m_current:.4f}, c = {c_current:.4f}\")\n",
        "\n",
        "print(\"------------------------------------------------\")\n",
        "print(f\"Final Result: y = {m_current:.2f}x + {c_current:.2f}\")\n",
        "print(f\"Actual Answer: y = 2.00x + 3.00\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD1DtttsYlMm",
        "outputId": "1e908578-d1ab-49a5-c345-66d113b7117f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: m = 0.6200, c = 0.1800\n",
            "Epoch 100: m = 2.4470, c = 1.3864\n",
            "Epoch 200: m = 2.3186, c = 1.8499\n",
            "Epoch 300: m = 2.2270, c = 2.1803\n",
            "Epoch 400: m = 2.1618, c = 2.4158\n",
            "Epoch 500: m = 2.1153, c = 2.5836\n",
            "Epoch 600: m = 2.0822, c = 2.7032\n",
            "Epoch 700: m = 2.0586, c = 2.7885\n",
            "Epoch 800: m = 2.0418, c = 2.8493\n",
            "Epoch 900: m = 2.0298, c = 2.8926\n",
            "------------------------------------------------\n",
            "Final Result: y = 2.02x + 2.92\n",
            "Actual Answer: y = 2.00x + 3.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradient Boosting(XGBOOST)**"
      ],
      "metadata": {
        "id": "mN_IBBsBM93z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load Data\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Initialize Gradient Boosting\n",
        "# n_estimators=100: We will have 100 \"shots\" (trees)\n",
        "# learning_rate=0.1: The size of each correction (step size from yesterday!)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# 3. Train (This takes longer than Random Forest!)\n",
        "print(\"Training Gradient Boosting... (Sequential = Slow)\")\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict & Evaluate\n",
        "y_pred = gb_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Gradient Boosting Accuracy: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LYZ6pqAiqlo",
        "outputId": "b2ebd2d4-617c-40fa-91f8-21a81f491302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Gradient Boosting... (Sequential = Slow)\n",
            "Gradient Boosting Accuracy: 96.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load Data\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Initialize XGBoost\n",
        "# use_label_encoder=False removes a warning\n",
        "# eval_metric='mlogloss' removes another warning\n",
        "model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, eval_metric='mlogloss')\n",
        "\n",
        "# 3. Train\n",
        "print(\"Training XGBoost...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"XGBoost Accuracy: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6VnYTzWNF1t",
        "outputId": "17166e66-ad8f-45a0-d83f-2e7d9e7ba4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost...\n",
            "XGBoost Accuracy: 96.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bdd4r0nmR8dm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}